{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credit: This notebook is based on the contents of  https://github.com/TeamHG-Memex/eli5/blob/master/notebooks/TextExplainer.ipynb"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging a black-box text classifier\n",
        "\nLetâ€™s look at the 20newsgroups dataset. This is a dataset that contains some discussions about news articles."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['alt.atheism', \n",
        "              'soc.religion.christian', \n",
        "              'comp.graphics', \n",
        "              'sci.med']\n",
        "twenty_train = fetch_20newsgroups(subset='train', \n",
        "                                  categories=categories, \n",
        "                                  shuffle=True,\n",
        "                                  random_state=42, \n",
        "                                  remove=('headers', 'footers'))\n",
        "twenty_test = fetch_20newsgroups(subset='test', \n",
        "                                 categories=categories, \n",
        "                                 shuffle=True,\n",
        "                                 random_state=42, \n",
        "                                 remove=('headers', 'footers'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "i = 125\n",
        "print(\"Class: {}\".format(twenty_train.target_names[twenty_train.target[i]]))\n",
        "print(\"-\"*20); print()\n",
        "sample = twenty_train.data[i]; print(sample)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a black-box classifier we use a kernel svm with LSA features. This is clearly non-linear and hard to interpret. "
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSA features\n",
        "vec = TfidfVectorizer(min_df=3, stop_words='english', ngram_range=(1, 2))\n",
        "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
        "lsa = make_pipeline(vec, svd)\n",
        "\n",
        "# SVM with rbf-kernel\n",
        "clf = SVC(C=150, gamma=2e-2, probability=True, kernel=\"rbf\")\n",
        "\n\n",
        "clf = SVC(C=150, gamma=2e-2, probability=True)\n",
        "pipe = make_pipeline(lsa, clf)\n",
        "pipe.fit(twenty_train.data, twenty_train.target)\n",
        "pipe.score(twenty_test.data, twenty_test.target)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimension of the input documents is reduced to 100, and then a kernel SVM is used to classify the documents.\n",
        "\nThis is what the pipeline returns for a document - it is pretty sure the first message in test data belongs to sci.med:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def print_prediction(doc):\n",
        "    y_pred = pipe.predict_proba([doc])[0]\n",
        "    for target, prob in zip(twenty_train.target_names, y_pred):\n",
        "        print(\"{:.3f} {}\".format(prob, target))    \n",
        "\n",
        "doc = twenty_test.data[0]\n",
        "print_prediction(doc)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm **cannot provide a good explanation for a black-box classifier which works on character level or uses features that are not directly related to tokens**, depending on the interpretable representation choosen. \n",
        "\n",
        "But one can use `eli5.lime.TextExplainer` to debug the prediction - to check what was important in the document to make this decision.\n",
        "\nCreate a `TextExplainer` instance, then pass the document to explain and a black-box classifier (a function which returns probabilities) to the TextExplainer.fit method, then check the explanation:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eli5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=twenty_train.target_names)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation makes sense - we expect reasonable classifier to take highlighted words in account. But how can we be sure this is how the pipeline works, not just a nice-looking lie? A simple sanity check is to remove or change the highlighted words, to confirm that they change the outcome:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "doc2 = re.sub(r'(recall|kidney|stones|medication|pain|tech)', '', doc, flags=re.I)\n",
        "print_prediction(doc2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicted probabilities changed a lot indeed.\n",
        "\n",
        "And in fact, `TextExplainer` did something similar to get the explanation. `TextExplainer` generated a lot of texts similar to the document (by removing some of the words), and then trained a white-box classifier which predicts the output of the black-box classifier (not the true labels!). The explanation we saw is for this white-box classifier.\n",
        "\n",
        "This approach follows the LIME algorithm; for text data the algorithm is actually pretty straightforward:\n",
        "\n",
        "1. generate distorted versions of the text;\n",
        "2. predict probabilities for these distorted texts using the black-box classifier;\n",
        "3. train another classifier (one of those eli5 supports) which tries to predict output of a black-box classifier on these texts.\n",
        "\n",
        "The algorithm works because even though it could be hard or impossible to approximate a black-box classifier globally (for every possible text), approximating it in a small neighbourhood near a given text often works well, even with simple white-box classifiers.\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "ExplainableMachineLearningShap.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}